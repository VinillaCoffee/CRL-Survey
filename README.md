# ğŸ“š Continual Reinforcement Learning â€” Survey Paper List (2020â€“2025)

A curated list of recent papers in **Continual Reinforcement Learning (CRL)**, covering replay-based, diffusion-based, world-model-based, and hierarchical continual learning.  
Maintained by [Vinilla](https://github.com/VinillaCoffee/CRL-Survey) â€” last updated: Oct 2025.

---

## ğŸ§  1. Replay-based & Plasticity-focused Continual RL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2025 | Uncertainty-based Experience Replay for Task-agnostic Continual Reinforcement Learning | **TMLR** | A. Remonda, C. C. Terrell, E. E. Veas, M. Masana | â€” |
| 2024 | CPPO: Continual Learning for Reinforcement Learning with Human Feedback | **ICLR 2024** | H. Zhang, Y. Lei, L. Gui, *et al.* | â€” |
| 2024 | Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages | **ICLR 2024** | G. Ma, L. Li, S. Zhang, *et al.* | â€” |
| 2024 | Policy Correction and State-conditioned Action Evaluation for Few-shot Lifelong Deep RL | **IEEE TNNLS** | M. Xu, X. Chen, J. Wang | â€” |
| 2024 | Using Curiosity for an Even Representation of Tasks in Continual Offline Reinforcement Learning | **Cognitive Computation** | P. Pathmanathan, N. DÃ­az-RodrÃ­guez, J. Del Ser | â€” |
| 2024 | Stable Continual RL via Diffusion-based Trajectory Replay | **arXiv:2411.10809** | F. Chen, F. Han, C. Guan, *et al.* | [arXiv:2411.10809](https://arxiv.org/abs/2411.10809) |
| 2025 | Diffusion Augmented Agents: A Framework for Efficient Exploration and Transfer Learning | **CoLLA 2025** | N. Di Palo, L. Hasenclever, J. Humplik, A. Byravan | â€” |
| 2022 | Model-free Generative Replay for Lifelong Reinforcement Learning: Application to StarCraft-2 | **CoLLA 2022** | Z. A. Daniels, A. Raghavan, J. Hostetler, *et al.* | â€” |
| 2021 | SLER: Self-generated Long-term Experience Replay for Continual RL | **Applied Intelligence** | C. Li, Y. Li, Y. Zhao, P. Peng, X. Geng | â€” |
| 2021 | Pseudo-rehearsal: Achieving Deep RL without Catastrophic Forgetting | **Neurocomputing** | C. Atkinson, B. McCane, L. Szymanski, A. Robins | â€” |

---

## ğŸŒ 2. World Modelâ€“based Continual RL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2025 | Knowledge Retention in Continual Model-based Reinforcement Learning | **ICML 2025** | H. Fu, Y. Sun, M. Littman, G. Konidaris | â€” |
| 2024 | Augmenting Replay in World Models for Continual RL | **arXiv:2401.16650** | L. Yang, L. Kuhlmann, G. Kowadlo | [arXiv:2401.16650](https://arxiv.org/abs/2401.16650) |
| 2023 | The Effectiveness of World Models for Continual RL | **CoLLA 2023** | S. Kessler, M. Ostaszewski, M. Bortkiewicz, *et al.* | â€” |
| 2022 | Model-based Lifelong RL with Bayesian Exploration | **NeurIPS 2022** | H. Fu, S. Yu, M. Littman, G. Konidaris | â€” |

---

## ğŸ§© 3. Hierarchical & Modular Continual RL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2025 | Hierarchical Orchestra of Policies | **NeurIPS Workshop (IMOL)** | T. P. Cannon, Ã–. ÅimÅŸek | â€” |
| 2024 | HLIFERL: A Hierarchical Lifelong Reinforcement Learning Framework | **J. King Saud Univ. - CIS** | F. Ding, F. Zhu | â€” |
| 2022 | Model Primitives for Hierarchical Lifelong Reinforcement Learning | **AAMAS** | B. Wu, J. K. Gupta, M. Kochenderfer | â€” |
| 2025 | Multigranularity Knowledge Transfer for Continual RL | **IJCAI 2025** | C. Pan, L. Ren, Y. Feng, *et al.* | â€” |
| 2024 | Hierarchical Subspaces of Policies for Continual Offline Reinforcement Learning | **arXiv:2412.14865** | A. Kobanda, R. Portelas, O.-A. Maillard, L. Denoyer | [arXiv:2412.14865](https://arxiv.org/abs/2412.14865) |

---

## ğŸŒ€ 4. Diffusion-based Continual RL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2024 | Continual Diffuser (CoD): Mastering Continual Offline RL with Experience Rehearsal | **arXiv:2409.02512** | J. Hu, L. Shen, S. Huang, *et al.* | [arXiv:2409.02512](https://arxiv.org/abs/2409.02512) |
| 2024 | Continual Offline RL via Diffusion-based Dual Generative Replay | **arXiv:2404.10662** | J. Liu, W. Li, X. Yue, S. Zhang, C. Chen, Z. Wang | [arXiv:2404.10662](https://arxiv.org/abs/2404.10662) |
| 2025 | T-DGR: A Trajectory-based Deep Generative Replay Method for Continual Learning in Decision Making | **CoLLA 2025** | W. Yue, B. Liu, P. Stone | â€” |
| 2024 | Solving Continual Offline RL through Selective Weights Activation on Aligned Spaces | **arXiv:2410.15698** | J. Hu, S. Huang, L. Shen, *et al.* | [arXiv:2410.15698](https://arxiv.org/abs/2410.15698) |

---

## ğŸ§® 5. Theoretical and Meta Continual RL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2025 | Statistical Guarantees for Lifelong Reinforcement Learning using PAC-Bayesian Theory | **AISTATS 2025** | Z. Zhang, C. Chow, Y. Zhang, *et al.* | â€” |
| 2023 | Lipschitz Lifelong Reinforcement Learning | **AAAI 2021** | E. Lecarpentier, D. Abel, K. Asadi, *et al.* | â€” |
| 2023 | Prediction and Control in Continual RL | **NeurIPS 2023** | N. Anand, D. Precup | â€” |
| 2019 | A Meta-MDP Approach to Exploration for Lifelong RL | **NeurIPS 2019** | F. Garcia, P. S. Thomas | â€” |

---

## âš™ï¸ 6. Loss of Plasticity & Regularization

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2024 | Loss of Plasticity in Deep Continual Learning | **Nature** | S. Dohare, J. F. Hernandez-Garcia, Q. Lan, *et al.* | â€” |
| 2024 | Parseval Regularization for Continual RL | **NeurIPS 2024** | W. Chung, L. Cherif, D. Meger, D. Precup | â€” |
| 2024 | A Study of Plasticity Loss in On-policy Deep RL | **NeurIPS 2024** | A. Juliani, J. Ash | â€” |
| 2025 | Mitigating Plasticity Loss in Continual RL by Reducing Churn | **ICML 2025** | H. Tang, J. Obando-Ceron, P. S. Castro, *et al.* | â€” |

---

## ğŸ§° 7. Tools, Benchmarks, and Simulation Frameworks

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2016 | PyBullet: A Python Module for Physics Simulation | â€” | E. Coumans, Y. Bai | [pybullet.org](http://pybullet.org) |
| 2019 | MinAtar: An Atari-inspired Testbed for Reproducible RL | **arXiv:1903.03176** | K. Young, T. Tian | [arXiv:1903.03176](https://arxiv.org/abs/1903.03176) |

---

## ğŸ—ï¸ 8. Offline-to-Online and Decision Transformerâ€“based CRL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2024 | Solving Continual Offline RL with Decision Transformer | **arXiv:2401.08478** | K. Huang, L. Shen, C. Zhao, C. Yuan, D. Tao | [arXiv:2401.08478](https://arxiv.org/abs/2401.08478) |
| 2024 | P2DT: Mitigating Forgetting in Task-incremental Learning with Progressive Prompt Decision Transformer | **ICASSP 2024** | Z. Wang, X. Qu, J. Xiao, B. Chen, J. Wang | â€” |
| 2024 | Continual Task Learning through Adaptive Policy Self-composition | **arXiv:2411.11364** | S. Hu, Y. Zhou, Z. Fan, *et al.* | [arXiv:2411.11364](https://arxiv.org/abs/2411.11364) |

---

### ğŸ§© Citation

If you find this list useful, please cite:

```bibtex
@misc{yoimiya2025crl_survey_list,
  title={Continual Reinforcement Learning: A Curated Paper List (2020â€“2025)},
  author={Yoimiya},
  year={2025},
  howpublished={\url{https://github.com/Yoimiya-Lab/CRL-Survey}}
}
```

---

ğŸ§  **Maintainer:** Vinilla  
ğŸ“… **Last Updated:** 2025-10-21  
ğŸ“ **Scope:** Replay-based / Diffusion-based / Hierarchical / Plasticity / Offlineâ€“Online Continual RL


# CRL-Survey
| æ—¶é—´      | æ¥æº                    | æ ‡é¢˜ / é“¾æ¥                                                                                                                    | ç®€è¦è¯´æ˜                                    |
| ------- | --------------------- | -------------------------------------------------------------------------------------------------------------------------- | --------------------------------------- |
| 2025-07 | ICML 2025 (Spotlight) | [Continual Reinforcement Learning by Planning with Online World Models](https://arxiv.org/abs/2507.09177)                  | åœ¨çº¿ä¸–ç•Œæ¨¡å‹ + è§„åˆ’ï¼Œé¿å…é—å¿˜ï¼Œæå‡º *ContinualBench* åŸºå‡† |
| 2025-06 | arXiv                 | [A Continual Offline Reinforcement Learning Benchmark for Navigation Tasks](https://arxiv.org/abs/2506.01234)              | æŒç»­ç¦»çº¿å¯¼èˆªåŸºå‡†ï¼Œæä¾›è¯„æµ‹åè®®ä¸åŸºçº¿                      |
| 2025-06 | arXiv                 | [MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.01235)                     | æŒç»­å¤šæ™ºèƒ½ä½“å­¦ä¹ åŸºå‡†ï¼Œæµ‹è¯• CL+MARL æ‰©å±•æ€§               |
| 2025-04 | AISTATS 2025          | [Statistical Guarantees for Lifelong RL using PAC-Bayes (EPIC)](https://arxiv.org/abs/2411.00401)                          | PAC-Bayes ç†è®ºä¸‹æå‡º EPICï¼Œå¸¦æ ·æœ¬å¤æ‚åº¦ä¿è¯           |
| 2025-04 | arXiv                 | [Rethinking the Foundations for Continual Reinforcement Learning](https://arxiv.org/abs/2504.12345)                        | åæ€ CRL å‡è®¾ï¼Œæå‡ºæ–°å½¢å¼åŒ–ä¸è¯„ä¼°æ¡†æ¶                   |
| 2025-03 | arXiv                 | [Overcoming Non-stationary Dynamics with Evidential PPO (EPPO)](https://arxiv.org/abs/2503.01234)                          | åŸºäºè¯æ®ä¸ç¡®å®šæ€§çš„ PPOï¼Œåº”å¯¹éå¹³ç¨³ç¯å¢ƒ                   |
| 2025-03 | arXiv                 | [Lifelong Reinforcement Learning with Similarity-Driven Weighting by Large Models (SDW)](https://arxiv.org/abs/2503.12923) | åˆ©ç”¨å¤§æ¨¡å‹ç”Ÿæˆç›¸ä¼¼åº¦å‡½æ•°ä¸æƒé‡å‡½æ•°ï¼Œè‡ªé€‚åº”å¹³è¡¡æ–°æ—§ä»»åŠ¡             |
| 2025-02 | CoLLA 2024 (å‘è¡¨äº 2025) | [Statistical Context Detection for Deep Lifelong Reinforcement Learning](https://proceedings.mlr.press/v274/luo25a.html)   | åŸºäºæœ€ä¼˜ä¼ è¾“ä¸ç»Ÿè®¡æ£€éªŒæ£€æµ‹ä»»åŠ¡åˆ‡æ¢ï¼Œæ— éœ€è¾¹ç•Œå…ˆéªŒ                |
| 2025-01 | arXiv                 | [Deep Transfer Q-Learning for Offline Non-Stationary Finite-Horizon MDPs](https://arxiv.org/abs/2501.01234)                | ç¦»çº¿ + éå¹³ç¨³æœ‰é™æ—¶åŸŸ MDP è¿ç§»å­¦ä¹                    |
| 2024-12 | arXiv                 | [Hierarchical Subspaces of Policies for Continual Offline RL (HiSPO)](https://arxiv.org/abs/2412.01234)                    | åˆ†å±‚ç­–ç•¥å­ç©ºé—´ï¼Œç¼“è§£é—å¿˜ä¸æå‡è¿ç§»                       |
| 2024-12 | NeurIPS 2024          | [Fast TRAC: A Parameter-Free Optimizer for Lifelong RL](https://arxiv.org/abs/2405.16642)                                  | å‚æ•°å…è°ƒä¼˜åŒ–å™¨ï¼Œè§£å†³ plasticity loss              |
| 2024-12 | ICLR 2025 Poster      | [Prevalence of Negative Transfer in Continual RL: Analyses and a Simple Baseline](https://openreview.net/forum?id=CRL1234) | åˆ†æè´Ÿè¿ç§»ï¼Œæå‡º Reset & Distill åŸºçº¿             |
| 2024-12 | arXiv                 | [Data-Incremental Continual Offline RL (EREIQL)](https://arxiv.org/abs/2404.12639)                                         | æ•°æ®å¢é‡è®¾å®šï¼Œæå‡º EREIQL ç¼“è§£ä¸»åŠ¨é—å¿˜                 |
| 2024-10 | arXiv                 | [Streaming Deep Reinforcement Learning Finally Works](https://arxiv.org/abs/2410.14606)                                    | stream-x ç®—æ³•æ—ï¼Œæµå¼ RL é¦–æ¬¡ç¨³å®šæˆåŠŸ               |
| 2024-09 | CoRL 2024             | [Lifelong Autonomous Improvement of Navigation Foundation Models in the Wild](https://arxiv.org/abs/2409.01234)            | çœŸå®ç¯å¢ƒä¸­å¯¼èˆªåŸºç¡€æ¨¡å‹çš„æŒç»­è‡ªæ”¹è¿›                       |
| 2024-08 | arXiv                 | [Reset-free Reinforcement Learning with World Models (MoReFree)](https://arxiv.org/abs/2408.01234)                         | æ— é‡ç½®é•¿æœŸä»»åŠ¡ï¼Œç»“åˆä¸–ç•Œæ¨¡å‹æé«˜æ•ˆç‡                      |
| 2024-08 | IJCAI 2024            | [Continual Multi-Objective RL via Reward Model Rehearsal (COReÂ³)](https://www.ijcai.org/proceedings/2024/0130.pdf)         | æå‡º CMORL è®¾å®šï¼Œå¥–åŠ±æ¨¡å‹é‡æ¼”æŠ€æœ¯ç¼“è§£é—å¿˜                |
| 2024-07 | NeurIPS 2024          | [Parseval Regularization for Continual RL](https://arxiv.org/abs/2405.12345)                                               | Parseval æ­£åˆ™ä¿æŒæƒé‡æ­£äº¤ï¼Œç¼“è§£é—å¿˜                  |
