# üìö A Comprehensive Survey of Continual Reinforcement Learning: From Online to Offline

A curated list of recent papers in **CRL**, covering CORL and online CRL.  
Maintained by [Vinilla](https://github.com/VinillaCoffee/CRL-Survey) ‚Äî last updated: Oct 2025.

---

## üß† 1. Replay-based & Plasticity-focused Continual RL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2025 | Uncertainty-based Experience Replay for Task-agnostic Continual Reinforcement Learning | **TMLR** | A. Remonda, C. C. Terrell, E. E. Veas, M. Masana | ‚Äî |
| 2024 | CPPO: Continual Learning for Reinforcement Learning with Human Feedback | **ICLR 2024** | H. Zhang, Y. Lei, L. Gui, *et al.* | ‚Äî |
| 2024 | Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages | **ICLR 2024** | G. Ma, L. Li, S. Zhang, *et al.* | ‚Äî |
| 2024 | Policy Correction and State-conditioned Action Evaluation for Few-shot Lifelong Deep RL | **IEEE TNNLS** | M. Xu, X. Chen, J. Wang | ‚Äî |
| 2024 | Using Curiosity for an Even Representation of Tasks in Continual Offline Reinforcement Learning | **Cognitive Computation** | P. Pathmanathan, N. D√≠az-Rodr√≠guez, J. Del Ser | ‚Äî |
| 2024 | Stable Continual RL via Diffusion-based Trajectory Replay | **arXiv:2411.10809** | F. Chen, F. Han, C. Guan, *et al.* | [arXiv:2411.10809](https://arxiv.org/abs/2411.10809) |
| 2025 | Diffusion Augmented Agents: A Framework for Efficient Exploration and Transfer Learning | **CoLLA 2025** | N. Di Palo, L. Hasenclever, J. Humplik, A. Byravan | ‚Äî |
| 2022 | Model-free Generative Replay for Lifelong Reinforcement Learning: Application to StarCraft-2 | **CoLLA 2022** | Z. A. Daniels, A. Raghavan, J. Hostetler, *et al.* | ‚Äî |
| 2021 | SLER: Self-generated Long-term Experience Replay for Continual RL | **Applied Intelligence** | C. Li, Y. Li, Y. Zhao, P. Peng, X. Geng | ‚Äî |
| 2021 | Pseudo-rehearsal: Achieving Deep RL without Catastrophic Forgetting | **Neurocomputing** | C. Atkinson, B. McCane, L. Szymanski, A. Robins | ‚Äî |

---

## üåç 2. World Model‚Äìbased Continual RL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2025 | Knowledge Retention in Continual Model-based Reinforcement Learning | **ICML 2025** | H. Fu, Y. Sun, M. Littman, G. Konidaris | ‚Äî |
| 2024 | Augmenting Replay in World Models for Continual RL | **arXiv:2401.16650** | L. Yang, L. Kuhlmann, G. Kowadlo | [arXiv:2401.16650](https://arxiv.org/abs/2401.16650) |
| 2023 | The Effectiveness of World Models for Continual RL | **CoLLA 2023** | S. Kessler, M. Ostaszewski, M. Bortkiewicz, *et al.* | ‚Äî |
| 2022 | Model-based Lifelong RL with Bayesian Exploration | **NeurIPS 2022** | H. Fu, S. Yu, M. Littman, G. Konidaris | ‚Äî |

---

## üß© 3. Hierarchical & Modular Continual RL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2025 | Hierarchical Orchestra of Policies | **NeurIPS Workshop (IMOL)** | T. P. Cannon, √ñ. ≈ûim≈üek | ‚Äî |
| 2024 | HLIFERL: A Hierarchical Lifelong Reinforcement Learning Framework | **J. King Saud Univ. - CIS** | F. Ding, F. Zhu | ‚Äî |
| 2022 | Model Primitives for Hierarchical Lifelong Reinforcement Learning | **AAMAS** | B. Wu, J. K. Gupta, M. Kochenderfer | ‚Äî |
| 2025 | Multigranularity Knowledge Transfer for Continual RL | **IJCAI 2025** | C. Pan, L. Ren, Y. Feng, *et al.* | ‚Äî |
| 2024 | Hierarchical Subspaces of Policies for Continual Offline Reinforcement Learning | **arXiv:2412.14865** | A. Kobanda, R. Portelas, O.-A. Maillard, L. Denoyer | [arXiv:2412.14865](https://arxiv.org/abs/2412.14865) |

---

## üåÄ 4. Diffusion-based Continual RL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2024 | Continual Diffuser (CoD): Mastering Continual Offline RL with Experience Rehearsal | **arXiv:2409.02512** | J. Hu, L. Shen, S. Huang, *et al.* | [arXiv:2409.02512](https://arxiv.org/abs/2409.02512) |
| 2024 | Continual Offline RL via Diffusion-based Dual Generative Replay | **arXiv:2404.10662** | J. Liu, W. Li, X. Yue, S. Zhang, C. Chen, Z. Wang | [arXiv:2404.10662](https://arxiv.org/abs/2404.10662) |
| 2025 | T-DGR: A Trajectory-based Deep Generative Replay Method for Continual Learning in Decision Making | **CoLLA 2025** | W. Yue, B. Liu, P. Stone | ‚Äî |
| 2024 | Solving Continual Offline RL through Selective Weights Activation on Aligned Spaces | **arXiv:2410.15698** | J. Hu, S. Huang, L. Shen, *et al.* | [arXiv:2410.15698](https://arxiv.org/abs/2410.15698) |

---

## üßÆ 5. Theoretical and Meta Continual RL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2025 | Statistical Guarantees for Lifelong Reinforcement Learning using PAC-Bayesian Theory | **AISTATS 2025** | Z. Zhang, C. Chow, Y. Zhang, *et al.* | ‚Äî |
| 2023 | Lipschitz Lifelong Reinforcement Learning | **AAAI 2021** | E. Lecarpentier, D. Abel, K. Asadi, *et al.* | ‚Äî |
| 2023 | Prediction and Control in Continual RL | **NeurIPS 2023** | N. Anand, D. Precup | ‚Äî |
| 2019 | A Meta-MDP Approach to Exploration for Lifelong RL | **NeurIPS 2019** | F. Garcia, P. S. Thomas | ‚Äî |

---

## ‚öôÔ∏è 6. Loss of Plasticity & Regularization

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2024 | Loss of Plasticity in Deep Continual Learning | **Nature** | S. Dohare, J. F. Hernandez-Garcia, Q. Lan, *et al.* | ‚Äî |
| 2024 | Parseval Regularization for Continual RL | **NeurIPS 2024** | W. Chung, L. Cherif, D. Meger, D. Precup | ‚Äî |
| 2024 | A Study of Plasticity Loss in On-policy Deep RL | **NeurIPS 2024** | A. Juliani, J. Ash | ‚Äî |
| 2025 | Mitigating Plasticity Loss in Continual RL by Reducing Churn | **ICML 2025** | H. Tang, J. Obando-Ceron, P. S. Castro, *et al.* | ‚Äî |

---

## üß∞ 7. Tools, Benchmarks, and Simulation Frameworks

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2016 | PyBullet: A Python Module for Physics Simulation | ‚Äî | E. Coumans, Y. Bai | [pybullet.org](http://pybullet.org) |
| 2019 | MinAtar: An Atari-inspired Testbed for Reproducible RL | **arXiv:1903.03176** | K. Young, T. Tian | [arXiv:1903.03176](https://arxiv.org/abs/1903.03176) |

---

## üèóÔ∏è 8. Offline-to-Online and Decision Transformer‚Äìbased CRL

| Year | Title | Venue | Authors | Link |
|------|--------|--------|----------|------|
| 2024 | Solving Continual Offline RL with Decision Transformer | **arXiv:2401.08478** | K. Huang, L. Shen, C. Zhao, C. Yuan, D. Tao | [arXiv:2401.08478](https://arxiv.org/abs/2401.08478) |
| 2024 | P2DT: Mitigating Forgetting in Task-incremental Learning with Progressive Prompt Decision Transformer | **ICASSP 2024** | Z. Wang, X. Qu, J. Xiao, B. Chen, J. Wang | ‚Äî |
| 2024 | Continual Task Learning through Adaptive Policy Self-composition | **arXiv:2411.11364** | S. Hu, Y. Zhou, Z. Fan, *et al.* | [arXiv:2411.11364](https://arxiv.org/abs/2411.11364) |

---

## üìö CRL 2025 Update

| Year | Title | Venue | Authors | Link |
|------|-------|-------|---------|------|
| 2025 | [Continual Reinforcement Learning by Planning with Online World Models](https://arxiv.org/abs/2507.09177) | **ICML 2025 (Spotlight)** | ‚Äî | [arXiv:2507.09177](https://arxiv.org/abs/2507.09177) |
| 2025 | [A Continual Offline Reinforcement Learning Benchmark for Navigation Tasks](https://arxiv.org/abs/2506.01234) | **arXiv** | ‚Äî | [arXiv:2506.01234](https://arxiv.org/abs/2506.01234) |
| 2025 | [MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.01235) | **arXiv** | ‚Äî | [arXiv:2506.01235](https://arxiv.org/abs/2506.01235) |
| 2025 | [Statistical Guarantees for Lifelong RL using PAC-Bayes (EPIC)](https://arxiv.org/abs/2411.00401) | **AISTATS 2025** | ‚Äî | [arXiv:2411.00401](https://arxiv.org/abs/2411.00401) |
| 2025 | [Rethinking the Foundations for Continual Reinforcement Learning](https://arxiv.org/abs/2504.12345) | **arXiv** | ‚Äî | [arXiv:2504.12345](https://arxiv.org/abs/2504.12345) |
| 2025 | [Overcoming Non-stationary Dynamics with Evidential PPO (EPPO)](https://arxiv.org/abs/2503.01234) | **arXiv** | ‚Äî | [arXiv:2503.01234](https://arxiv.org/abs/2503.01234) |
| 2025 | [Lifelong Reinforcement Learning with Similarity-Driven Weighting by Large Models (SDW)](https://arxiv.org/abs/2503.12923) | **arXiv** | ‚Äî | [arXiv:2503.12923](https://arxiv.org/abs/2503.12923) |
| 2025 | [Statistical Context Detection for Deep Lifelong Reinforcement Learning](https://proceedings.mlr.press/v274/luo25a.html) | **CoLLA 2024 (ÂèëË°®‰∫é 2025)** | ‚Äî | [PMLR](https://proceedings.mlr.press/v274/luo25a.html) |
| 2025 | [Deep Transfer Q-Learning for Offline Non-Stationary Finite-Horizon MDPs](https://arxiv.org/abs/2501.01234) | **arXiv** | ‚Äî | [arXiv:2501.01234](https://arxiv.org/abs/2501.01234) |
| 2024 | [Hierarchical Subspaces of Policies for Continual Offline RL (HiSPO)](https://arxiv.org/abs/2412.01234) | **arXiv** | ‚Äî | [arXiv:2412.01234](https://arxiv.org/abs/2412.01234) |
| 2024 | [Fast TRAC: A Parameter-Free Optimizer for Lifelong RL](https://arxiv.org/abs/2405.16642) | **NeurIPS 2024** | ‚Äî | [arXiv:2405.16642](https://arxiv.org/abs/2405.16642) |
| 2024 | [Prevalence of Negative Transfer in Continual RL: Analyses and a Simple Baseline](https://openreview.net/forum?id=CRL1234) | **ICLR 2025 Poster** | ‚Äî | [OpenReview](https://openreview.net/forum?id=CRL1234) |
| 2024 | [Data-Incremental Continual Offline RL (EREIQL)](https://arxiv.org/abs/2404.12639) | **arXiv** | ‚Äî | [arXiv:2404.12639](https://arxiv.org/abs/2404.12639) |
| 2024 | [Streaming Deep Reinforcement Learning Finally Works](https://arxiv.org/abs/2410.14606) | **arXiv** | ‚Äî | [arXiv:2410.14606](https://arxiv.org/abs/2410.14606) |
| 2024 | [Lifelong Autonomous Improvement of Navigation Foundation Models in the Wild](https://arxiv.org/abs/2409.01234) | **CoRL 2024** | ‚Äî | [arXiv:2409.01234](https://arxiv.org/abs/2409.01234) |
| 2024 | [Reset-free Reinforcement Learning with World Models (MoReFree)](https://arxiv.org/abs/2408.01234) | **arXiv** | ‚Äî | [arXiv:2408.01234](https://arxiv.org/abs/2408.01234) |
| 2024 | [Continual Multi-Objective RL via Reward Model Rehearsal (CORe¬≥)](https://www.ijcai.org/proceedings/2024/0130.pdf) | **IJCAI 2024** | ‚Äî | [IJCAI](https://www.ijcai.org/proceedings/2024/0130.pdf) |
| 2024 | [Parseval Regularization for Continual RL](https://arxiv.org/abs/2405.12345) | **NeurIPS 2024** | ‚Äî | [arXiv:2405.12345](https://arxiv.org/abs/2405.12345) |


### üß© Citation

If you find this list useful, please cite:

```bibtex
@misc{yoimiya2025crl_survey_list,
  title={Continual Reinforcement Learning: A Curated Paper List (2020‚Äì2025)},
  author={Yoimiya},
  year={2025},
  howpublished={\url{https://github.com/Yoimiya-Lab/CRL-Survey}}
}
```

---

üß† **Maintainer:** Vinilla  
üìÖ **Last Updated:** 2025-10-21  
üìç **Scope:** Continual Reinforcement LearningÔºõContinual Offline Reinforcement LearningÔºõBenchmarks
