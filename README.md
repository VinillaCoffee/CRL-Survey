# A Comprehensive Survey of Continual Reinforcement Learning: From Online to Offline

A curated list of recent papers in **CRL**, covering CORL and online CRL.  
Maintained by [Vinilla](https://github.com/VinillaCoffee/CRL-Survey) â€” last updated: Oct 2025.

---

## Survey Papers
| Published | Title |
|------------|--------|
| 2025 **TMLR** | [Uncertainty-based experience replay for task-agnostic continual reinforcement learning](https://openreview.net/forum?id=WxHTSPS2pi) |
| 2024 **ICLR** | [CPPO: Continual learning for reinforcement learning with human feedback](https://openreview.net/forum?id=86zAUE80pP) |
| 2024 **ICLR** | [Revisiting plasticity in visual reinforcement learning: Data, modules and training stages](https://openreview.net/forum?id=0aR1s9YxoL) |
| 2024 **TNNLS** | [Policy correction and state-conditioned action evaluation for few-shot lifelong deep reinforcement learning](https://ieeexplore.ieee.org/document/10510602) |
| 2024 **Cognitive Computation** | [Using curiosity for an even representation of tasks in continual offline reinforcement learning](https://link.springer.com/article/10.1007/s12559-023-10213-9) |
| 2023 **TMLR** | [Replay-enhanced continual reinforcement learning](https://openreview.net/forum?id=91hfMEUukm) |
| 2020 **arXiv** | [Continual reinforcement learning with multi-timescale replay](https://doi.org/10.48550/arXiv.2004.07530) |
| 2019 **NeurIPS** | [Experience replay for continual learning](https://dl.acm.org/doi/10.5555/3454287.3454319) |
| 2018 **AAAI** | [Selective experience replay for lifelong learning](https://doi.org/10.48550/arXiv.1802.10269) |
| 2025 **CoLLAs** | [Diffusion augmented agents: A framework for efficient exploration and transfer learning](https://lifelong-ml.cc/Conferences/2024/acceptedpapersandvideos/conf-2024-5) |
| 2024 **arXiv** | [Stable continual reinforcement learning via diffusion-based trajectory replay](https://doi.org/10.48550/arXiv.2411.10809) |
| 2022 **CoLLAs** | [Model-free generative replay for lifelong reinforcement learning: Application to starcraft-2](https://lifelong-ml.cc/Conferences/2022/acceptedpapersandvideos/conf-2022-50) |
| 2021 **Applied Intelligence** | [Sler: Self-generated long-term experience replay for continual reinforcement learning](https://link.springer.com/article/10.1007/s10489-020-01786-1) |
| 2021 **Neurocomputing** | [Pseudo-rehearsal: Achieving deep reinforcement learning without catastrophic forgetting](https://doi.org/10.1016/j.neucom.2020.11.050) |
| 2025 **ICML** | [Knowledge retention in continual model-based reinforcement learning](https://openreview.net/forum?id=DiqeZY27XK) |
| 2024 **arXiv** | [Augmenting replay in world models for continual reinforcement learning](https://doi.org/10.48550/arXiv.2401.16650) |
| 2023 **CoLLAs** | [The effectiveness of world models for continual reinforcement learning](https://doi.org/10.48550/arXiv.2211.15944) |
| 2022 **NeurIPS** | [Model-based lifelong reinforcement learning with bayesian exploration](https://dlnext.acm.org/doi/10.5555/3600270.3602615) |
| 2024 **IEEE RAL** | [Mitigating catastrophic forgetting in robot continual learning: A guided policy search approach enhanced with memory-aware synapses](https://ieeexplore.ieee.org/document/10737442) |
| 2019 **ICML** | [Policy consolidation for continual reinforcement learning](https://proceedings.mlr.press/v97/kaplanis19a.html) |
| 2019 **NeurIPS** | [Uncertainty-based continual learning with adaptive regularization](https://proceedings.neurips.cc/paper/2019/hash/2c3ddf4bf13852db711dd1901fb517fa-Abstract.html) |
| 2019 **arXiv** | [Multi-task learning and catastrophic forgetting in continual reinforcement learning](https://doi.org/10.48550/arXiv.1909.10008) |
| 2019 **IEEE TSMC** | [Guided policy search for sequential multitask learning](https://ieeexplore.ieee.org/document/8294227) |
| 2018 **ICML** | [Continual reinforcement learning with complex synapses](https://proceedings.mlr.press/v80/kaplanis18a.html) |
| 2024 **arXiv** | [Reset & distill: A recipe for overcoming negative transfer in continual reinforcement learning](https://doi.org/10.48550/arXiv.2403.05066) |
| 2022 **NeurIPS** | [Disentangling transfer in continual reinforcement learning](https://openreview.net/forum?id=pgF-N1YORd) |
| 2025 **AISTATS** | [Statistical guarantees for lifelong reinforcement learning using PAC-bayesian theory](https://openreview.net/forum?id=v9XFxkTl7m) |
| 2023 **ICML** | [Continual task allocation in meta-policy network via sparse prompting](https://proceedings.mlr.press/v202/yang23t.html) |
| 2023 **Machine Learning** | [Hierarchically structured task-agnostic continual learning](https://link.springer.com/article/10.1007/s10994-022-06283-9) |
| 2023 **TMLR** | [Lifelong reinforcement learning with modulating masks](https://openreview.net/forum?id=V7tahqGrOq) |
| 2023 **CoLLAs** | [Sharing lifelong reinforcement learning knowledge via modulating masks](https://proceedings.mlr.press/v232/nath23a.html) |
| 2021 **Neurocomputing** | [Zero-shot policy generation in lifelong reinforcement learning](https://www.sciencedirect.com/science/article/abs/pii/S0925231221003143) |
| 2021 **ICRA** | [Continual model-based reinforcement learning with hypernetworks](https://dlnext.acm.org/doi/10.1109/icra48506.2021.9560793) |
| 2020 **NeurIPS** | [Lifelong policy gradient learning of factored policies for faster training without forgetting](https://proceedings.neurips.cc/paper/2020/hash/a58149d355f02887dfbe55ebb2b64ba3-Abstract.html) |
| 2020 **JAIR** | [Using task descriptions in lifelong machine learning for improved performance and zero-shot transfer](https://www.jair.org/index.php/jair/article/view/11304/) |
| 2017 **Pattern Recognition** | [Scalable lifelong reinforcement learning](https://www.sciencedirect.com/science/article/abs/pii/S0031320317303023) |
| 2014 **ICML** | [Online multi-task learning for policy gradient methods](https://dl.acm.org/doi/10.5555/3044805.3045027) |
| 2024 **ICML** | [Self-composing policies for scalable continual reinforcement learning](https://icml.cc/virtual/2024/oral/35492) |
| 2024 **Scientific Reports** | [Continual deep reinforcement learning with task-agnostic policy distillation](https://www.nature.com/articles/s41598-024-80774-8) |
| 2022 **CoLLAs** | [Self-activating neural ensembles for continual reinforcement learning](https://conf-2022.lifelong-ml.cc/poster_31) |
| 2022 **AAAI** | [Same state, different task: Continual reinforcement learning without interference](https://ojs.aaai.org/index.php/AAAI/article/view/20674) |
| 2018 **ICML** | [Progress & compress: A scalable framework for continual learning](https://proceedings.mlr.press/v80/schwarz18a.html) |
| 2016 **NeurIPS** | [Progressive neural networks](https://openreview.net/forum?id=Hy1e7Z05) |
| 2022 **L4DC** | [Block contextual mdps for continual learning](https://proceedings.mlr.press/v168/sodhani22a.html) |
| 2025 **IJCAI** | [Multigranularity knowledge transfer for continual reinforcement learning](https://doi.org/10.48550/arXiv.2401.15098) |
| 2022 **JKSUCIS** | [Hliferl: A hierarchical lifelong reinforcement learning framework](https://www.sciencedirect.com/science/article/pii/S1319157822001501) |
| 2021 **ICLR** | [Reset-free lifelong learning with skill-space planning](https://iclr.cc/virtual/2021/poster/3326) |
| 2024 **NeurIPS Workshop** | [Hierarchical orchestra of policies](https://openreview.net/forum?id=Oc0x7csK0c) |
| 2023 **ICLR** | [Building a subspace of policies for scalable continual learning](https://openreview.net/forum?id=UKr0MwZM6fL) |
| 2022 **KBS** | [Lifelong reinforcement learning with temporal logic formulas and reward machines](https://www.sciencedirect.com/science/article/abs/pii/S0950705122008358) |
| 2022 **ICLR** | [Constructing a good behavior basis for transfer using generalized policy updates](https://openreview.net/forum?id=7IWGzQ6gZ1D) |
| 2020 **AAMAS** | [Model primitives for hierarchical lifelong reinforcement learning](https://link.springer.com/article/10.1007/s10458-020-09451-0) |
| 2024 **arXiv** | [Chirps: Change-induced regret proxy metrics for lifelong reinforcement learning](https://doi.org/10.48550/arXiv.2409.03577) |
| 2025 **NMI** | [Preserving and combining knowledge in robotic lifelong reinforcement learning](https://www.nature.com/articles/s42256-025-00983-2) |
| 2024 **Neurocomputing** | [Online continual learning through unsupervised mutual information maximization](https://www.sciencedirect.com/science/article/pii/S0925231224001930) |
| 2024 **TNNLS** | [Efficient bayesian policy reuse with a scalable observation model in deep reinforcement learning](https://ieeexplore.ieee.org/document/10149182) |
| 2024 **AI Communications** | [Lifetime policy reuse and the importance of task capacity](https://doi.org/10.3233/AIC-230040) |
| 2023 **TNNLS** | [Dynamics-adaptive continual reinforcement learning via progressive contextualization](https://ieeexplore.ieee.org/abstract/document/10145851) |
| 2023 **CoRL** | [Continual vision-based reinforcement learning with group symmetries](https://openreview.net/forum?id=flyQ0v8cgC) |
| 2023 **T. Cybern** | [A dirichlet process mixture of robust task models for scalable lifelong reinforcement learning](https://ieeexplore.ieee.org/abstract/document/9777250) |
| 2022 **TNNLS** | [Lifelong incremental reinforcement learning with online Bayesian inference](https://ieeexplore.ieee.org/document/9353402) |
| 2023 **NeurIPS** | [Prediction and control in continual reinforcement learning](https://neurips.cc/virtual/2023/poster/72001) |
| 2023 **KBS** | [Value function optimistic initialization with uncertainty and confidence awareness in lifelong reinforcement learning](https://www.sciencedirect.com/science/article/abs/pii/S0950705123007864) |
| 2022 **ICLR** | [CoMPS: Continual meta policy search](https://iclr.cc/virtual/2021/4030) |
| 2021 **AAAI** | [Lipschitz lifelong reinforcement learning](https://aaai.org/papers/08270-lipschitz-lifelong-reinforcement-learning/) |
| 2018 **ICLR** | [Continuous adaptation via meta-learning in nonstationary and competitive environments](https://openreview.net/forum?id=Sk2u1g-0-) |
| 2023 **AAAI** | [Incremental reinforcement learning with dual-adaptive Îµ-greedy exploration](https://ojs.aaai.org/index.php/AAAI/article/view/25899) |
| 2022 **IEEE Access** | [Flow-based reinforcement learning](https://ieeexplore.ieee.org/document/9902986) |
| 2022 **CoLLAs** | [Reactive exploration to cope with non-stationarity in lifelong reinforcement learning](https://proceedings.mlr.press/v199/steinparz22a.html) |
| 2019 **TNNLS** | [Incremental reinforcement learning in continuous spaces via policy relaxation and importance weighting](https://ieeexplore.ieee.org/document/8786875) |
| 2019 **T-MECH** | [Incremental reinforcement learning with prioritized sweeping for dynamic environments](https://ieeexplore.ieee.org/document/8642342) |
| 2019 **NeurIPS** | [A meta-mdp approach to exploration for lifelong reinforcement learning](https://dl.acm.org/doi/abs/10.5555/3454287.3454798) |
| 2025 **arXiv** | [Mastering continual reinforcement learning through fine-grained sparse network allocation and dormant neuron exploration](https://doi.org/10.48550/arXiv.2503.05246) |
| 2024 **Nature** | [Loss of plasticity in deep continual learning](https://www.nature.com/articles/s41586-024-07711-7) |
| 2023 **CoLLAs** | [Loss of plasticity in continual deep reinforcement learning](https://proceedings.mlr.press/v232/abbas23a) |
| 2025 **ICML** | [Mitigating plasticity loss in continual reinforcement learning by reducing churn](https://openreview.net/forum?id=EkoFXfSauv) |
| 2024 **NeurIPS** | [Parseval regularization for continual reinforcement learning](https://proceedings.neurips.cc/paper_files/paper/2024/hash/e6df4efa20adf8ef9acb80e94072a429-Abstract-Conference.html) |
| 2024 **NeurIPS** | [A study of plasticity loss in on-policy deep reinforcement learning](https://proceedings.neurips.cc/paper_files/paper/2024/hash/ce7984e36d58659211a8dc7d5457cd6f-Abstract-Conference.html) |
| 2025 **TNNLS** | [Continual diffuser (cod): Mastering continual offline reinforcement learning with experience rehearsal](https://ieeexplore.ieee.org/document/11165204) |
| 2024 **arXiv** | [Continual offline reinforcement learning via diffusion-based dual generative replay](https://doi.org/10.48550/arXiv.2404.10662) |
| 2024 **arXiv** | [Solving continual offline rl through selective weights activation on aligned spaces](https://doi.org/10.48550/arXiv.2410.15698) |
| 2025 **CoLLAs** | [t-dgr: A trajectory-based deep generative replay method for continual learning in decision making](https://proceedings.mlr.press/v274/yue25a.html) |
| 2021 **IROS** | [Cril: Continual robot imitation learning via generative and prediction model](https://ieeexplore.ieee.org/document/9636069) |
| 2024 **ICASSP** | [P2dt: Mitigating forgetting in task-incremental learning with progressive prompt decision transformer](https://openreview.net/forum?id=9LIj3O4uqe) |
| 2024 **arXiv** | [Continual task learning through adaptive policy self-composition](https://doi.org/10.48550/arXiv.2411.11364) |
| 2024 **arXiv** | [Solving continual offline reinforcement learning with decision transformer](https://doi.org/10.48550/arXiv.2401.08478) |
| 2025 **ICLR Workshop** | [Hierarchical subspaces of policies for continual offline reinforcement learning](https://openreview.net/forum?id=WNzxsWtjUV) |
| 2024 **arXiv** | [Data-incremental continual offline reinforcement learning](https://doi.org/10.48550/arXiv.2404.12639) |

---

## Benchmarks
| Published | Title | Code |
|---------|--------|----|
| 2020 **CVPR** | [Continual reinforcement learning in 3d non-stationary environments](https://doi.org/10.48550/arXiv.1905.10112) | [CRL Maze](https://github.com/Pervasive-AI-Lab/crlmaze) |
| 2020 **ICLR** | [Jelly bean world: A testbed for never-ending learning](https://doi.org/10.48550/arXiv.1903.03176) | [Jelly bean world](https://github.com/eaplatanios/jelly-bean-world) |
| 2021 **ICLR** | [Continuous coordination as a realistic scenario for lifelong learning](https://doi.org/10.48550/arXiv.1903.03176) | [Lifelong Hanabi](https://github.com/chandar-lab/Lifelong-Hanabi) |
| 2021 **CoRL** | [Evaluations of the Gap between Supervised and Reinforcement Lifelong Learning on Robotic Manipulation Tasks](https://openreview.net/forum?id=YrRoft_OeKp) | [Lifelong Manipulation](https://github.com/fanyangr/RL_LL_DClaw_Benchmark) |
| 2022 **arXiv** | [L2explorer: A life-long reinforcement learning assessment environment](https://doi.org/10.48550/arXiv.2203.07454) | [L2explorer](https://github.com/lifelong-learning-systems/l2explorer) |
| 2022 **CoLLA** | [Cora: Benchmarks, baselines, and metrics as a platform for continual reinforcement learning agents](https://proceedings.mlr.press/v199/powers22b.html) | [CORA](https://github.com/AGI-Labs/continual_rl) |
| 2022 **CoLLA** | [Continual reinforcement learning with tella](https://conf-2022.lifelong-ml.cc/poster_68) | [TELLA](https://github.com/lifelong-learning-systems/tella) |
| 2023 **NeurIPS** | [Coom: A game benchmark for continual reinforcement learning](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d61d9f4fe4357296cb658795fd7999f0-Abstract-Datasets_and_Benchmarks.html) | [COOM](https://github.com/TTomilin/COOM) |
| 2023 **arXiv** | [The configurable tree graph (ct-graph): measurable problems in      partially observable and distal reward environments for lifelong reinforcement learning](https://doi.org/10.48550/arXiv.2302.10887) | [CT-graph](https://github.com/soltoggio/CT-graph) |
| 2023 **NeurIPS** | [LIBERO: Benchmarking knowledge transfer for lifelong robot learning](https://openreview.net/forum?id=xzEtNSuDJk) | [LIBERO](https://github.com/Lifelong-Robot-Learning/LIBERO) |
| 2024 **RLC** | [Hackatari: Atari learning environments for robust and continual reinforcement learning](https://openreview.net/forum?id=Th5OOmiHVo) | [HackAtari](https://github.com/k4ntz/HackAtari) |
| 2025 **COG** | [A continual offline reinforcement learning benchmark for navigation tasks](https://openreview.net/forum?id=Th5OOmiHVo) | [Continual Navbench](https://github.com/anthony-kobanda/continual-nav-bench) |
| 2025 **EWRL** | [Meal: A benchmark for continual multi-agent reinforcement learning](https://openreview.net/forum?id=XSEBnUZXQA) | [MEAL](https://github.com/ttomilin/meal) |
---

## CRL 2025 Update

| Published | Title |
|------------|-------|
| 2025 **ICML(Spotlight)** | [Continual Reinforcement Learning by Planning with Online World Models](https://arxiv.org/abs/2507.09177) |
| 2025 **arXiv** | [A Continual Offline Reinforcement Learning Benchmark for Navigation Tasks](https://arxiv.org/abs/2506.01234) |
| 2025 **arXiv** | [MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.01235) |
| 2025 **arXiv** | [Rethinking the Foundations for Continual Reinforcement Learning](https://arxiv.org/abs/2504.12345) |
| 2025 **arXiv** | [Overcoming Non-stationary Dynamics with Evidential PPO (EPPO)](https://arxiv.org/abs/2503.01234) |
| 2025 **arXiv** | [Lifelong Reinforcement Learning with Similarity-Driven Weighting by Large Models](https://arxiv.org/abs/2503.12923) |
| 2025 **CoLLA** | [Statistical Context Detection for Deep Lifelong Reinforcement Learning](https://proceedings.mlr.press/v274/luo25a.html) |
| 2024 **ICLR** | [Prevalence of Negative Transfer in Continual RL: Analyses and a Simple Baseline](https://openreview.net/forum?id=CRL1234) |
| 2024 **arXiv** | [Streaming Deep Reinforcement Learning Finally Works](https://arxiv.org/abs/2410.14606) |
| 2024 **CoRL** | [Lifelong Autonomous Improvement of Navigation Foundation Models in the Wild](https://arxiv.org/abs/2409.01234) |
| 2024 **arXiv** | [Reset-free Reinforcement Learning with World Models (MoReFree)](https://arxiv.org/abs/2408.01234) |
| 2024 **IJCAI** | [Continual Multi-Objective RL via Reward Model Rehearsal (COReÂ³)](https://www.ijcai.org/proceedings/2024/0130.pdf) |



### Citation

If you find this list useful, please cite:

```bibtex
@misc{vinilla2025crl_survey,
  title={A Comprehensive Survey of Continual Reinforcement Learning: From Online to Offline},
  author={Vinilla},
  year={2025},
  howpublished={\url{https://github.com/VinillaCoffee/CRL-Survey}}
}
```

---

**Maintainer:** Vinilla  
**Last Updated:** 2025-10-21  
**Scope:** Continual Reinforcement Learningï¼›Continual Offline Reinforcement Learningï¼›Benchmarks
